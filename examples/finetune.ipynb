{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune Embedding Model\n",
    "\n",
    "此笔记本包含使用 Uniem 库对模型进行微调的示例，在运行此 notebook 之前，我们需要先安装了 Uniem 库，安装方式如下。\n",
    "\n",
    "```bash\n",
    "pip install uniem\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install uniem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**微调模型的方式非常简单，只需要按照指定的格式准备数据就可以了，其余的事情都将由 uniem 替你完成，几行代码就够了，就像下面👇🏻这样**\n",
    "\n",
    "```python\n",
    "from datasets import load_dataset\n",
    "from uniem.finetuner import FineTuner\n",
    "\n",
    "dataset = load_dataset('shibing624/nli_zh', 'STS-B')\n",
    "finetuner = FineTuner('moka-ai/m3e-small', dataset=dataset)\n",
    "finetuner.run(epochs=1)\n",
    "```\n",
    "\n",
    "## 数据准备\n",
    "\n",
    "你需要准备 `uniem` 支持的数据格式的数据集\n",
    "\n",
    "目前，`uniem` 支持一下三种格式\n",
    "\n",
    "1. `PairRecord`\n",
    "2. `TripletRecord`\n",
    "3. `ScoredPairRecord`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record_types: ['pair', 'triplet', 'scored_pair']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from uniem.data_structures import RecordType, PairRecord, TripletRecord, ScoredPairRecord\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "warnings.filterwarnings('ignore')\n",
    "print(f'record_types: {[record_type.value for record_type in RecordType]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PairRecord\n",
    "\n",
    "当你的数据集中只有问答对或者相似句子的正例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair_record: PairRecord(text='肾结石如何治疗？', text_pos='如何治愈肾结石')\n"
     ]
    }
   ],
   "source": [
    "pair_record = PairRecord(text='肾结石如何治疗？', text_pos='如何治愈肾结石')\n",
    "print(f'pair_record: {pair_record}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TripletRecord\n",
    "\n",
    "当你的数据集中同时有问答或者句子的正例和负例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triplet_record: TripletRecord(text='肾结石如何治疗？', text_pos='如何治愈肾结石', text_neg='胆结石有哪些治疗方法？')\n"
     ]
    }
   ],
   "source": [
    "triplet_record = TripletRecord(text='肾结石如何治疗？', text_pos='如何治愈肾结石', text_neg='胆结石有哪些治疗方法？')\n",
    "print(f'triplet_record: {triplet_record}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ScoredPairRecord\n",
    "\n",
    "当你的数据集是一个二分类任务，或者能给出实际相似分数\n",
    "\n",
    "#### 二分类任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scored_pair_record: ScoredPairRecord(sentence1='肾结石如何治疗？', sentence2='如何治愈肾结石', label=1.0)\n",
      "scored_pair_record: ScoredPairRecord(sentence1='肾结石如何治疗？', sentence2='胆结石有哪些治疗方法？', label=0.0)\n"
     ]
    }
   ],
   "source": [
    "scored_pair_record1 = ScoredPairRecord(sentence1='肾结石如何治疗？', sentence2='如何治愈肾结石', label=1.0)\n",
    "scored_pair_record2 = ScoredPairRecord(sentence1='肾结石如何治疗？', sentence2='胆结石有哪些治疗方法？', label=0.0)\n",
    "print(f'scored_pair_record: {scored_pair_record1}')\n",
    "print(f'scored_pair_record: {scored_pair_record2}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 相似分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scored_pair_record: ScoredPairRecord(sentence1='肾结石如何治疗？', sentence2='如何治愈肾结石', label=2.0)\n",
      "scored_pair_record: ScoredPairRecord(sentence1='肾结石如何治疗？', sentence2='胆结石有哪些治疗方法？', label=1.0)\n",
      "scored_pair_record: ScoredPairRecord(sentence1='肾结石如何治疗？', sentence2='失眠如何治疗', label=0)\n"
     ]
    }
   ],
   "source": [
    "scored_pair_record1 = ScoredPairRecord(sentence1='肾结石如何治疗？', sentence2='如何治愈肾结石', label=2.0)\n",
    "scored_pair_record2 = ScoredPairRecord(sentence1='肾结石如何治疗？', sentence2='胆结石有哪些治疗方法？', label=1.0)\n",
    "scored_pair_record3 = ScoredPairRecord(sentence1='肾结石如何治疗？', sentence2='失眠如何治疗', label=0)\n",
    "print(f'scored_pair_record: {scored_pair_record1}')\n",
    "print(f'scored_pair_record: {scored_pair_record2}')\n",
    "print(f'scored_pair_record: {scored_pair_record3}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 示例：STS-B\n",
    "\n",
    "现在我们假设我们想要 HuggingFace 上托管的 STS-B 数据集上做微调\n",
    "\n",
    "让我我们先把数据集下载好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset nli_zh (/Users/wangyuxin/.cache/huggingface/datasets/shibing624___nli_zh/STS-B/1.0.0/65b555276ee420c801e1c9eb830db959e37f42fa60c68c8b07a4448b8c436706)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf18b58a3854b17b610172a9aa36801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "stsb_dataset_dict = load_dataset('shibing624/nli_zh', 'STS-B')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们查看一下 STS-B 的数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': '一架飞机要起飞了。', 'sentence2': '一架飞机正在起飞。', 'label': 5}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stsb_dataset_dict['train'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们发现 STS-B 数据集正好符合我们 `ScoredPairRecord` 的数据格式，因此我们可以直接进行微调不需要任何的数据转换。\n",
    "\n",
    "我们只需要使用 `uniem` 提供的 `FineTuner` 就可以使用 3 行代码完成微调\n",
    "\n",
    "注意： `FineTuner` 集成了 HuggingFace 的 datasets 生态，原生支持类型为 `datasets.Dataset` 或者 `datasets.DatasetDict` 的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset nli_zh (/Users/wangyuxin/.cache/huggingface/datasets/shibing624___nli_zh/STS-B/1.0.0/65b555276ee420c801e1c9eb830db959e37f42fa60c68c8b07a4448b8c436706)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272fbb372a7a4d2499e7714228acb1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start with seed: 42\n",
      "Output dir: finetuned-model\n",
      "Start training for 1 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78f71e618344fd180f224e500b155cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Saving model\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from uniem.finetuner import FineTuner\n",
    "\n",
    "dataset = load_dataset('shibing624/nli_zh', 'STS-B')\n",
    "# 指定训练的模型为 m3e-small\n",
    "finetuner = FineTuner('moka-ai/m3e-small', dataset=dataset)\n",
    "finetuner.run(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json             special_tokens_map.json tokenizer_config.json\n",
      "pytorch_model.bin       tokenizer.json          vocab.txt\n"
     ]
    }
   ],
   "source": [
    "# 训练过程完成后，会自动保存模型到 finetuned-model 目录下\n",
    "!ls finetuned-model/model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 示例： Jsonl \n",
    "\n",
    "现在我们要对一个猜谜的数据集进行微调，这个数据集是通过 json line 的形式存储的。\n",
    "\n",
    "让我先看看数据格式吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': '猜谜语：一身卷卷细毛，吃的青青野草，过了数九寒冬，无私献出白毛。 （打一动物）', 'output': '谜底：白羊'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('example_data/riddle.jsonl', lines=True)\n",
    "df.iloc[0].to_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个数据集中，我们有 `instruction` 和 `output` ，我们可以把这两者结合在一起组成一个相似句对。这是一个典型的 `PairRecord` 数据集。\n",
    "\n",
    "`PairRecord` 需要 `text` 和 `text_pos` 两个字段，因此我们需要对数据集的列进行重新命名，以符合 `PairRecord` 的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start with seed: 42\n",
      "Output dir: finetuned-model-riddle\n",
      "Start training for 1 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222589bd4cc043ed84ba43db0b4502b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Saving model\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from uniem.finetuner import FineTuner\n",
    "\n",
    "# 读取 jsonl 文件\n",
    "df = pd.read_json('example_data/riddle.jsonl', lines=True)\n",
    "# 重新命名\n",
    "df = df.rename(columns={'instruction': 'text', 'output': 'text_pos'})\n",
    "# 指定训练的模型为 m3e-small\n",
    "finetuner = FineTuner('moka-ai/m3e-small', dataset=df.to_dict('records'))\n",
    "finetuner.run(epochs=1, output_dir='finetuned-model-riddle')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的两个示例分别展示了对 jsonl 本地 `PairRecord`类型数据集，以及 huggingface 远程 `ScoredPair` 类型数据集的读取和训练过程。`TripletRecord` 类型的数据集的读取和训练过程与 `PairRecord` 类型的数据集的读取和训练过程类似，这里就不再赘述了。\n",
    "\n",
    "也就是说，你只要构造了符合 `uniem` 支持的数据格式的数据集，就可以使用 `FineTuner` 对你的模型进行微调了。\n",
    "\n",
    "`FineTuner` 接受的 dataset 参数，只要是可以迭代的产生有指定字段（格式）的字典 `dict` 就行了，所以上述示例分别使用 `datasets.DatasetDict` 和 `list[dict]` 两种数据格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uniem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
